{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "YUPMSTIwgDUX"
      },
      "source": [
        "![CRISP-DM](https://raw.githubusercontent.com/zaratsian/Spark/master/nfl_banner2.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxKQnNZpgDUa"
      },
      "source": [
        "## Use Case:  Predicting NFL plays"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5TU-bCggDUb"
      },
      "source": [
        "## Loading Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gAjWzfss5nB"
      },
      "source": [
        "# Install Spark dependencies\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!rm spark-3.5.1-bin-hadoop3.tgz\n",
        "!wget --no-cookies --no-check-certificate https://dlcdn.apache.org/spark/spark-3.5.1/spark-3.5.1-bin-hadoop3.tgz\n",
        "!tar zxvf spark-3.5.1-bin-hadoop3.tgz\n",
        "!pip install -q findspark\n",
        "!pip install pyspark==3.5.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbtsIJwBgDUc"
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"]  = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.1-bin-hadoop3\"\n",
        "\n",
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "import datetime, time\n",
        "import re, random, sys\n",
        "from pyspark.sql.types import StructType, StructField, ArrayType, IntegerType, StringType, FloatType, LongType, DateType\n",
        "from pyspark.sql.functions import struct, array, lit, monotonically_increasing_id, col, expr, when, concat, udf, split, size, lag, count, isnull\n",
        "from pyspark.sql import Window\n",
        "from pyspark.ml.linalg import Vectors\n",
        "from pyspark.ml.regression import GBTRegressor, LinearRegression, GeneralizedLinearRegression, RandomForestRegressor\n",
        "from pyspark.ml.classification import GBTClassifier, RandomForestClassifier\n",
        "from pyspark.ml.feature import VectorIndexer, VectorAssembler, StringIndexer, IndexToString\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml import Pipeline, PipelineModel\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, RegressionEvaluator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibznxCWCgDUg"
      },
      "source": [
        "# Initialize Spark Session\n",
        "spark = SparkSession.builder.appName(\"Spark NFL Predictions\").master(\"local[*]\").getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4lFP7FZgDUj"
      },
      "source": [
        "## Data Ingestion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rbCOB_3gDUp"
      },
      "source": [
        "### Download Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMoXBsC7uprL"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/zaratsian/Datasets/master/NFLPlaybyPlay.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9kPiGZOupEc"
      },
      "source": [
        "### Load data into Spark Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkjkgkipgDUq"
      },
      "source": [
        "schema = StructType([\n",
        "    StructField(\"id\", IntegerType()),\n",
        "    StructField(\"Date\", DateType()),\n",
        "    StructField(\"GameID\", IntegerType()),\n",
        "    StructField(\"Drive\", IntegerType()),\n",
        "    StructField(\"qtr\", IntegerType()),\n",
        "    StructField(\"down\", StringType()),\n",
        "    StructField(\"time\", StringType()),\n",
        "    StructField(\"TimeUnder\", IntegerType()),\n",
        "    StructField(\"TimeSecs\", StringType()),\n",
        "    StructField(\"PlayTimeDiff\", StringType()),\n",
        "    StructField(\"SideofField\", StringType()),\n",
        "    StructField(\"yrdln\", StringType()),\n",
        "    StructField(\"yrdline100\", StringType()),\n",
        "    StructField(\"ydstogo\", IntegerType()),\n",
        "    StructField(\"ydsnet\", IntegerType()),\n",
        "    StructField(\"GoalToGo\", StringType()),\n",
        "    StructField(\"FirstDown\", StringType()),\n",
        "    StructField(\"posteam\", StringType()),\n",
        "    StructField(\"DefensiveTeam\", StringType()),\n",
        "    StructField(\"desc\", StringType()),\n",
        "    StructField(\"PlayAttempted\", IntegerType()),\n",
        "    StructField(\"Yards_Gained\", IntegerType()),\n",
        "    StructField(\"sp\", IntegerType()),\n",
        "    StructField(\"Touchdown\", IntegerType()),\n",
        "    StructField(\"ExPointResult\", StringType()),\n",
        "    StructField(\"TwoPointConv\", StringType()),\n",
        "    StructField(\"DefTwoPoint\", StringType()),\n",
        "    StructField(\"Safety\", IntegerType()),\n",
        "    StructField(\"PuntResult\", StringType()),\n",
        "    StructField(\"PlayType\", StringType()),\n",
        "    StructField(\"Passer\", StringType()),\n",
        "    StructField(\"PassAttempt\", IntegerType()),\n",
        "    StructField(\"PassOutcome\", StringType()),\n",
        "    StructField(\"PassLength\", StringType()),\n",
        "    StructField(\"PassLocation\", StringType()),\n",
        "    StructField(\"InterceptionThrown\", IntegerType()),\n",
        "    StructField(\"Interceptor\", StringType()),\n",
        "    StructField(\"Rusher\", StringType()),\n",
        "    StructField(\"RushAttempt\", IntegerType()),\n",
        "    StructField(\"RunLocation\", StringType()),\n",
        "    StructField(\"RunGap\", StringType()),\n",
        "    StructField(\"Receiver\", StringType()),\n",
        "    StructField(\"Reception\", IntegerType()),\n",
        "    StructField(\"ReturnResult\", StringType()),\n",
        "    StructField(\"Returner\", StringType()),\n",
        "    StructField(\"BlockingPlayer\", StringType()),\n",
        "    StructField(\"Tackler1\", StringType()),\n",
        "    StructField(\"Tackler2\", StringType()),\n",
        "    StructField(\"FieldGoalResult\", StringType()),\n",
        "    StructField(\"FieldGoalDistance\", StringType()),\n",
        "    StructField(\"Fumble\", IntegerType()),\n",
        "    StructField(\"RecFumbTeam\", StringType()),\n",
        "    StructField(\"RecFumbPlayer\", StringType()),\n",
        "    StructField(\"Sack\", IntegerType()),\n",
        "    StructField(\"Challenge.Replay\", IntegerType()),\n",
        "    StructField(\"ChalReplayResult\", StringType()),\n",
        "    StructField(\"Accepted.Penalty\", IntegerType()),\n",
        "    StructField(\"PenalizedTeam\", StringType()),\n",
        "    StructField(\"PenaltyType\", StringType()),\n",
        "    StructField(\"PenalizedPlayer\", StringType()),\n",
        "    StructField(\"Penalty.Yards\", IntegerType()),\n",
        "    StructField(\"PosTeamScore\", StringType()),\n",
        "    StructField(\"DefTeamScore\", StringType()),\n",
        "    StructField(\"ScoreDiff\", StringType()),\n",
        "    StructField(\"AbsScoreDiff\", StringType()),\n",
        "    StructField(\"Season\", IntegerType())\n",
        "])\n",
        "\n",
        "rawdata = spark.read.load('NFLPlaybyPlay.csv', format=\"csv\", header=True, schema=schema)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upprPZnZ3z--"
      },
      "source": [
        "rawdata.show(10,False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zETYN9oBgDUu"
      },
      "source": [
        "## Data Cleaning, Transformations, Enrichment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4_K17NngDUv"
      },
      "source": [
        "### Data Cleaning & Transformations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTBnFATvgDUw"
      },
      "source": [
        "columns_to_keep =   [\n",
        "                    \"Date\", \"GameID\", \"Drive\", \"qtr\", \"down\", \"time\", \"TimeUnder\", \"TimeSecs\",\n",
        "                    \"PlayTimeDiff\", \"yrdline100\", \"ydstogo\", \"ydsnet\", \"FirstDown\", \"posteam\",\n",
        "                    \"DefensiveTeam\", \"Yards_Gained\", \"Touchdown\", \"PlayType\", \"PassLength\",\n",
        "                    \"PassLocation\", \"RunLocation\",\n",
        "                    #\"Passer\", \"Rusher\", \"InterceptionThrown\", \"Season\"\n",
        "                    \"PosTeamScore\", \"DefTeamScore\"\n",
        "                    ]\n",
        "\n",
        "# Filter columns (keep)\n",
        "nfldata = rawdata.select(columns_to_keep)\n",
        "\n",
        "# Drop rows with NAa:\n",
        "nfldata = nfldata.filter(nfldata.down != 'NA')\n",
        "\n",
        "# approxQuantile\n",
        "nfldata.approxQuantile(col='Yards_Gained', probabilities=[0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], relativeError=0.05)\n",
        "\n",
        "# Filter target variable (Yards_Gained) to remove outliers\n",
        "nfldata = nfldata.filter( (col('Yards_Gained') <= 20 ) & (col('Yards_Gained') >= -5 ) )\n",
        "nfldata.approxQuantile(col='Yards_Gained', probabilities=[0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], relativeError=0.05)\n",
        "\n",
        "numeric_columns     = [c[0] for c in nfldata.dtypes if c[1] not in ['string','timestamp']]\n",
        "categorical_columns = [c[0] for c in nfldata.dtypes if c[1] in ['string']]\n",
        "datetime_columns    = [c[0] for c in nfldata.dtypes if c[1] in ['timestamp']]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDi06NJTgDU0"
      },
      "source": [
        "### Data Enrichment & Additional Transformations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6gEI99xgDU1"
      },
      "source": [
        "nfldata2 = nfldata.withColumn(\"Date\",            col(\"Date\"))                       \\\n",
        "                    .withColumn(\"GameID\",       col(\"GameID\").cast(\"int\"))          \\\n",
        "                    .withColumn(\"Drive\",        col(\"Drive\").cast(\"int\"))           \\\n",
        "                    .withColumn(\"qtr\",          col(\"qtr\").cast(\"int\"))             \\\n",
        "                    .withColumn(\"down\",         col(\"down\").cast(\"int\"))            \\\n",
        "                    .withColumn(\"time\",         col(\"time\").cast(\"string\"))         \\\n",
        "                    .withColumn(\"TimeUnder\",    col(\"TimeUnder\").cast(\"int\"))       \\\n",
        "                    .withColumn(\"TimeSecs\",     col(\"TimeSecs\").cast(\"int\"))        \\\n",
        "                    .withColumn(\"PlayTimeDiff\", col(\"PlayTimeDiff\").cast(\"int\"))    \\\n",
        "                    .withColumn(\"yrdline100\",   col(\"yrdline100\").cast(\"int\"))      \\\n",
        "                    .withColumn(\"ydstogo\",      col(\"ydstogo\").cast(\"int\"))         \\\n",
        "                    .withColumn(\"ydsnet\",       col(\"ydsnet\").cast(\"int\"))          \\\n",
        "                    .withColumn(\"FirstDown\",    col(\"FirstDown\").cast(\"int\"))       \\\n",
        "                    .withColumn(\"posteam\",      col(\"posteam\").cast(\"string\"))      \\\n",
        "                    .withColumn(\"DefensiveTeam\",col(\"DefensiveTeam\").cast(\"string\"))\\\n",
        "                    .withColumn(\"Yards_Gained\", col(\"Yards_Gained\").cast(\"int\"))    \\\n",
        "                    .withColumn(\"Touchdown\",    col(\"Touchdown\").cast(\"int\"))       \\\n",
        "                    .withColumn(\"PlayType\",     col(\"PlayType\").cast(\"string\"))     \\\n",
        "                    .withColumn(\"PassLength\",   col(\"PassLength\").cast(\"string\"))   \\\n",
        "                    .withColumn(\"PassLocation\", col(\"PassLocation\").cast(\"string\")) \\\n",
        "                    .withColumn(\"RunLocation\",  col(\"RunLocation\").cast(\"string\"))  \\\n",
        "                    .withColumn(\"PosTeamScore\", col(\"PosTeamScore\").cast(\"int\"))    \\\n",
        "                    .withColumn(\"DefTeamScore\", col(\"DefTeamScore\").cast(\"int\"))\n",
        "\n",
        "\n",
        "numeric_columns     = [c[0] for c in nfldata2.dtypes if c[1] not in ['string','timestamp']]\n",
        "categorical_columns = [c[0] for c in nfldata2.dtypes if c[1] in ['string']]\n",
        "datetime_columns    = [c[0] for c in nfldata2.dtypes if c[1] in ['timestamp']]\n",
        "\n",
        "# Category Levels\n",
        "[nfldata2.select(nfldata2[c]).groupBy(nfldata2[c]).count().show(5,False) for c in categorical_columns]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxsG77SxgDU4"
      },
      "source": [
        "### Data Enrichment & Additional Transformations (Continued...)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bE9UQsAwgDU5"
      },
      "source": [
        "# Filter - Keep where Playtype in ['Run','Pass']\n",
        "nfldata2 = nfldata2.filter( (nfldata2.PlayType==\"Run\") | (nfldata2.PlayType==\"Pass\") )\n",
        "\n",
        "# Derive Date var(s)\n",
        "nfldata2 = nfldata2.withColumn(\"month_day\", concat(nfldata2[\"Date\"].substr(6,2), nfldata2[\"Date\"].substr(9,2)).cast(\"int\") )\n",
        "\n",
        "# Lag (Get previous PlayType)\n",
        "w = Window().partitionBy('GameID','Drive').orderBy('GameID','Drive', col('TimeSecs').desc())\n",
        "nfldata2 = nfldata2.withColumn(\"PlayType_lag\", lag(\"PlayType\").over(w) ) \\\n",
        "                 .withColumn(\"PlayType_lag\",  when( isnull('PlayType_lag'), 'FirstPlay').otherwise( col('PlayType_lag') ) ) \\\n",
        "                 .orderBy('GameID','Drive', col('TimeSecs').desc())\n",
        "\n",
        "# Print Results\n",
        "#nfldata2.select([\"GameID\",\"Drive\",\"qtr\",\"down\",\"TimeSecs\",\"PlayType\",\"PlayType_lag\",\"yrdline100\",\"posteam\",\"month_day\"]).show(50,False)\n",
        "\n",
        "# Split into \"Run\" and \"Pass\" (I want to build two models)\n",
        "nfldata2_run  = nfldata2.filter( col('PlayType')=='Run' )\n",
        "nfldata2_pass = nfldata2.filter( col('PlayType')=='Pass' )\n",
        "\n",
        "print(\"Total Number of Records:   \" + str(nfldata2.count()))\n",
        "print(\"Number of Running Records: \" + str(nfldata2_run.count()))\n",
        "print(\"Number of Passing Records: \" + str(nfldata2_pass.count()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwplP0cxgDV8"
      },
      "source": [
        "## Model Building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-omfCOIgDV9"
      },
      "source": [
        "### Split into Train and Test\n",
        "NOTE: You can use a randomsplit or something a little bit more appropriate like a [cross validator](https://spark.apache.org/docs/latest/ml-tuning.html#cross-validation)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXJ0pOCIgDV-"
      },
      "source": [
        "training_run, testing_run   = nfldata2_run.randomSplit([0.8, 0.2], seed=12345)\n",
        "training_pass, testing_pass = nfldata2_pass.randomSplit([0.8, 0.2], seed=12345)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkga8ydLgDWB"
      },
      "source": [
        "### Building Model Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqwMHWiZgDWC"
      },
      "source": [
        "# Prepare string variables so that they can be used by the decision tree algorithm\n",
        "# StringIndexer encodes a string column of labels to a column of label indices\n",
        "si1 = StringIndexer(inputCol=\"PlayType\", outputCol=\"PlayType_index\")\n",
        "si2 = StringIndexer(inputCol=\"PlayType_lag\", outputCol=\"PlayType_lag_index\")\n",
        "si3 = StringIndexer(inputCol=\"PassLength\", outputCol=\"PassLength_index\")\n",
        "si4 = StringIndexer(inputCol=\"PassLocation\", outputCol=\"PassLocation_index\")\n",
        "si5 = StringIndexer(inputCol=\"RunLocation\", outputCol=\"RunLocation_index\")\n",
        "\n",
        "target   = 'Yards_Gained'\n",
        "features = ['qtr','down','TimeSecs','yrdline100','ydstogo','ydsnet','month_day','PlayType_lag_index']\n",
        "\n",
        "#encode the Label column: feature indexer\n",
        "fi = StringIndexer(inputCol='Yards_Gained', outputCol='label').fit(training_run)\n",
        "\n",
        "# Pipelines API requires that input variables are passed in  a vector\n",
        "va  = VectorAssembler(inputCols=features, outputCol=\"features\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PNT8OhVgDWE"
      },
      "source": [
        "# run the algorithm and build model taking the default settings\n",
        "rfr = RandomForestRegressor(featuresCol=\"label\", labelCol=target, predictionCol=\"prediction\", maxDepth=5, maxBins=350, seed=12345)\n",
        "gbr = GBTRegressor(featuresCol=\"features\", labelCol=target, predictionCol=\"prediction\", maxDepth=5, maxBins=350, seed=12345)\n",
        "\n",
        "# Convert indexed labels back to original labels, label converter\n",
        "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\", labels=fi.labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIcZzrSYgDWI"
      },
      "source": [
        "### Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mY_iW1MgDWI"
      },
      "source": [
        "# Build the machine learning pipeline\n",
        "pipeline_run  = Pipeline(stages=[si2, fi, va, gbr, labelConverter])\n",
        "\n",
        "# Build model.\n",
        "# The fitted model from a Pipeline is a PipelineModel, which consists of fitted models and transformers, corresponding to the pipeline stages.\n",
        "model_run = pipeline_run.fit(training_run)\n",
        "\n",
        "# store the predictions on training data on HDFS\n",
        "#model_run.write().overwrite().save('hdfs://dzaratsian0.field.hortonworks.com:8020/models/nfl_model_run3')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsneV1cfzjNJ"
      },
      "source": [
        "#dir(model_run.stages[-2])#.featureImportances\n",
        "model_run.stages[-2].featureImportances\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mK0EXD7zgDWM"
      },
      "source": [
        "## Making predictions against the Trained Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQFrGRvQgDWN"
      },
      "source": [
        "# Make predictions.\n",
        "predictions = model_run.transform(testing_run)\n",
        "# show the results\n",
        "predictions.show(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ie_aeTXHgDWQ"
      },
      "source": [
        "### Generate results of classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2cSMohfgDWQ"
      },
      "source": [
        "predictions=predictions.select(predictions[\"Yards_Gained\"],predictions[\"predictedLabel\"],predictions[\"prediction\"])\n",
        "type(predictions)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1XdWELsgDWU"
      },
      "source": [
        "predictions.show(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWJRGHxXgDWW"
      },
      "source": [
        "### Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qsCGzjRgDWX"
      },
      "source": [
        "# Evaluate Results\n",
        "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=target)  # rmse (default)|mse|r2|mae\n",
        "RMSE = evaluator.evaluate(predictions)\n",
        "print('RMSE: ' + str(RMSE))\n",
        "\n",
        "evaluator = RegressionEvaluator(metricName=\"mae\", labelCol=target)  # rmse (default)|mse|r2|mae\n",
        "MAE = evaluator.evaluate(predictions) # Mean Absolute Error\n",
        "print('MSE: ' + str(MAE))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QSYa7L53I_Qj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}