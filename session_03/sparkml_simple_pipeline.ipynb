{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-7vRh7EGS30"
      },
      "source": [
        "## **PySpark Machine Learning**\n",
        "###Pipeline Example ([Docs](https://spark.apache.org/docs/latest/ml-pipeline.html))\n",
        "\n",
        "In machine learning, it's common to run a series of steps for data prep, cleansing, feature engineering, and then ultimately model training (among several other potential steps).\n",
        "\n",
        "Spark ML Pipelines sequences these steps into an ordered array (or DAG). A Pipeline is specified as a sequence of stages, and each stage is either a **Transformer** or an **Estimator**.\n",
        "\n",
        "It's often a best practice to save a model or a pipeline to disk for later use.\n",
        "\n",
        "Below is an example Spark ML Pipeline that shows two Transformers (Tokenizer and HashingTF) and one Estimator (Logistic Regression)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcHwihQDCpaf"
      },
      "source": [
        "<img src=\"https://spark.apache.org/docs/latest/img/ml-Pipeline.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZ24BRz6FMwN"
      },
      "source": [
        "## **Install Spark Dependencies**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upqpisH2IoMy"
      },
      "source": [
        "# Install Spark dependencies\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!rm spark-3.5.1-bin-hadoop3.tgz\n",
        "!wget --no-cookies --no-check-certificate https://dlcdn.apache.org/spark/spark-3.5.1/spark-3.5.1-bin-hadoop3.tgz\n",
        "!tar zxvf spark-3.5.1-bin-hadoop3.tgz\n",
        "!pip install -q findspark\n",
        "!pip install pyspark==3.5.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2xvv-QnsQZs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb74a484-6083-4de2-eee1-34441148c843"
      },
      "source": [
        "!ls -al | grep spark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drwxr-xr-x 13 1000 1000      4096 Feb 15 11:36 spark-3.5.1-bin-hadoop3\n",
            "-rw-r--r--  1 root root 400446614 Feb 15 11:39 spark-3.5.1-bin-hadoop3.tgz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvMtRJwUFzie"
      },
      "source": [
        "## **Import Python and PySpark Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-SIpC_-aw0t"
      },
      "source": [
        "# Set up required environment variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"]  = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.1-bin-hadoop3\"\n",
        "\n",
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.feature import HashingTF, Tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyT917EuF7Pv"
      },
      "source": [
        "## **Initialize Spark Session**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niAz2S672M_m"
      },
      "source": [
        "spark = SparkSession.builder.appName(\"Spark ML Pipeline Example\").master(\"local[*]\").getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hL4NPf_ZF_OF"
      },
      "source": [
        "## **Load Sample Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udgQ-I48MRrV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2fc65d5-df82-4f3c-cc9b-64c2950b9eb2"
      },
      "source": [
        "training = spark.createDataFrame([\n",
        "    (0, \"a b c d e spark\", 1.0),\n",
        "    (1, \"b d\", 0.0),\n",
        "    (2, \"spark f g h\", 1.0),\n",
        "    (3, \"hadoop mapreduce\", 0.0)\n",
        "], [\"id\", \"text\", \"label\"])\n",
        "\n",
        "training.show(10,False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----------------+-----+\n",
            "|id |text            |label|\n",
            "+---+----------------+-----+\n",
            "|0  |a b c d e spark |1.0  |\n",
            "|1  |b d             |0.0  |\n",
            "|2  |spark f g h     |1.0  |\n",
            "|3  |hadoop mapreduce|0.0  |\n",
            "+---+----------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9qcdXwEMZqY"
      },
      "source": [
        "## **Configure Pipeline Objects**\n",
        "Transforms (tokenizer and hashingTF) and Estimators (logistic regression)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4WCZ13oMltr"
      },
      "source": [
        "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
        "hashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol=\"features\")\n",
        "lr = LogisticRegression(maxIter=10, regParam=0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "VKOwIinjkyq9",
        "outputId": "90ecee0f-34c4-4dcb-b145-d2795271ed39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.ml.feature.Tokenizer"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pyspark.ml.feature.Tokenizer</b><br/>def __init__(*, inputCol: Optional[str]=None, outputCol: Optional[str]=None)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/pyspark/ml/feature.py</a>A tokenizer that converts the input string to lowercase and then\n",
              "splits it by white spaces.\n",
              "\n",
              ".. versionadded:: 1.3.0\n",
              "\n",
              "Examples\n",
              "--------\n",
              "&gt;&gt;&gt; df = spark.createDataFrame([(&quot;a b c&quot;,)], [&quot;text&quot;])\n",
              "&gt;&gt;&gt; tokenizer = Tokenizer(outputCol=&quot;words&quot;)\n",
              "&gt;&gt;&gt; tokenizer.setInputCol(&quot;text&quot;)\n",
              "Tokenizer...\n",
              "&gt;&gt;&gt; tokenizer.transform(df).head()\n",
              "Row(text=&#x27;a b c&#x27;, words=[&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;])\n",
              "&gt;&gt;&gt; # Change a parameter.\n",
              "&gt;&gt;&gt; tokenizer.setParams(outputCol=&quot;tokens&quot;).transform(df).head()\n",
              "Row(text=&#x27;a b c&#x27;, tokens=[&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;])\n",
              "&gt;&gt;&gt; # Temporarily modify a parameter.\n",
              "&gt;&gt;&gt; tokenizer.transform(df, {tokenizer.outputCol: &quot;words&quot;}).head()\n",
              "Row(text=&#x27;a b c&#x27;, words=[&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;])\n",
              "&gt;&gt;&gt; tokenizer.transform(df).head()\n",
              "Row(text=&#x27;a b c&#x27;, tokens=[&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;])\n",
              "&gt;&gt;&gt; # Must use keyword arguments to specify params.\n",
              "&gt;&gt;&gt; tokenizer.setParams(&quot;text&quot;)\n",
              "Traceback (most recent call last):\n",
              "    ...\n",
              "TypeError: Method setParams forces keyword arguments.\n",
              "&gt;&gt;&gt; tokenizerPath = temp_path + &quot;/tokenizer&quot;\n",
              "&gt;&gt;&gt; tokenizer.save(tokenizerPath)\n",
              "&gt;&gt;&gt; loadedTokenizer = Tokenizer.load(tokenizerPath)\n",
              "&gt;&gt;&gt; loadedTokenizer.transform(df).head().tokens == tokenizer.transform(df).head().tokens\n",
              "True</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 5197);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kT_dTa7LpkdK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42a55e78-9dca-4d51-9ea0-d1512cc6ec77"
      },
      "source": [
        "tokenizer.transform(training).show(5, False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----------------+-----+----------------------+\n",
            "|id |text            |label|words                 |\n",
            "+---+----------------+-----+----------------------+\n",
            "|0  |a b c d e spark |1.0  |[a, b, c, d, e, spark]|\n",
            "|1  |b d             |0.0  |[b, d]                |\n",
            "|2  |spark f g h     |1.0  |[spark, f, g, h]      |\n",
            "|3  |hadoop mapreduce|0.0  |[hadoop, mapreduce]   |\n",
            "+---+----------------+-----+----------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLnHzeSgMsIX"
      },
      "source": [
        "## **Create Pipeline Object**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4ip4waqMwLd"
      },
      "source": [
        "pipeline = Pipeline(stages=[tokenizer, hashingTF, lr])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgaJUUnVMy10"
      },
      "source": [
        "## **Run Pipeline to transform data and train model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uotehx7bM42W"
      },
      "source": [
        "model = pipeline.fit(training)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYuCIf6tM8ot"
      },
      "source": [
        "## **Test Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hC6C3wKwyBbt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d6cfaaf-370c-4159-ed3e-19300c1c4a1a"
      },
      "source": [
        "test = spark.createDataFrame([\n",
        "    (4, \"spark i j k\"),\n",
        "    (5, \"l m n\"),\n",
        "    (6, \"spark hadoop spark\"),\n",
        "    (7, \"apache hadoop\")\n",
        "], [\"id\", \"text\"])\n",
        "\n",
        "# Make predictions on test documents and print columns of interest.\n",
        "prediction = model.transform(test)\n",
        "prediction.show(10,False)\n",
        "#selected = prediction.select(\"id\", \"text\", \"probability\", \"prediction\")\n",
        "#for row in selected.collect():\n",
        "#    rid, text, prob, prediction = row\n",
        "#    print(\"(%d, %s) --> prob=%s, prediction=%f\" % (rid, text, str(prob), prediction))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------------------+----------------------+------------------------------------------------------+----------------------------------------+----------------------------------------+----------+\n",
            "|id |text              |words                 |features                                              |rawPrediction                           |probability                             |prediction|\n",
            "+---+------------------+----------------------+------------------------------------------------------+----------------------------------------+----------------------------------------+----------+\n",
            "|4  |spark i j k       |[spark, i, j, k]      |(262144,[19036,68693,173558,213660],[1.0,1.0,1.0,1.0])|[0.5288285522796787,-0.5288285522796787]|[0.6292098489668484,0.3707901510331516] |0.0       |\n",
            "|5  |l m n             |[l, m, n]             |(262144,[1303,52644,248090],[1.0,1.0,1.0])            |[4.169141395340047,-4.169141395340047]  |[0.984770006762304,0.015229993237696027]|0.0       |\n",
            "|6  |spark hadoop spark|[spark, hadoop, spark]|(262144,[173558,198017],[2.0,1.0])                    |[-1.8649814141188976,1.8649814141188976]|[0.13412348342566158,0.8658765165743384]|1.0       |\n",
            "|7  |apache hadoop     |[apache, hadoop]      |(262144,[68303,198017],[1.0,1.0])                     |[5.415644272001838,-5.415644272001838]  |[0.9955732114398529,0.00442678856014711]|0.0       |\n",
            "+---+------------------+----------------------+------------------------------------------------------+----------------------------------------+----------------------------------------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3bwkWkYvE8Uv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}